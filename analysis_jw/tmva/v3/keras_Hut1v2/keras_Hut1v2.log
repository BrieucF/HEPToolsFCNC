Train on 70000 samples, validate on 20000 samples
Epoch 1/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.7289 - acc: 0.6090Epoch 00000: val_loss improved from inf to 0.07228, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 47s - loss: 0.7287 - acc: 0.6091 - val_loss: 0.0723 - val_acc: 0.6413
Epoch 2/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.6295 - acc: 0.6518Epoch 00001: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.6295 - acc: 0.6518 - val_loss: 0.0725 - val_acc: 0.6476
Epoch 3/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.6181 - acc: 0.6626Epoch 00002: val_loss improved from 0.07228 to 0.07095, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.6181 - acc: 0.6627 - val_loss: 0.0710 - val_acc: 0.6530
Epoch 4/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.6690Epoch 00003: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.6113 - acc: 0.6688 - val_loss: 0.0710 - val_acc: 0.6565
Epoch 5/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.6719Epoch 00004: val_loss improved from 0.07095 to 0.07030, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.6087 - acc: 0.6718 - val_loss: 0.0703 - val_acc: 0.6560
Epoch 6/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.6056 - acc: 0.6745Epoch 00005: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.6055 - acc: 0.6746 - val_loss: 0.0705 - val_acc: 0.6565
Epoch 7/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.6761Epoch 00006: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.6033 - acc: 0.6761 - val_loss: 0.0705 - val_acc: 0.6585
Epoch 8/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.6002 - acc: 0.6778Epoch 00007: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.6004 - acc: 0.6777 - val_loss: 0.0704 - val_acc: 0.6562
Epoch 9/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.6800Epoch 00008: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5997 - acc: 0.6799 - val_loss: 0.0703 - val_acc: 0.6607
Epoch 10/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5970 - acc: 0.6819Epoch 00009: val_loss improved from 0.07030 to 0.07019, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.5969 - acc: 0.6819 - val_loss: 0.0702 - val_acc: 0.6579
Epoch 11/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5945 - acc: 0.6842Epoch 00010: val_loss improved from 0.07019 to 0.06982, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.5945 - acc: 0.6843 - val_loss: 0.0698 - val_acc: 0.6597
Epoch 12/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5949 - acc: 0.6819Epoch 00011: val_loss improved from 0.06982 to 0.06963, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.5950 - acc: 0.6818 - val_loss: 0.0696 - val_acc: 0.6592
Epoch 13/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5921 - acc: 0.6865Epoch 00012: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5921 - acc: 0.6866 - val_loss: 0.0702 - val_acc: 0.6622
Epoch 14/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5914 - acc: 0.6856Epoch 00013: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5913 - acc: 0.6857 - val_loss: 0.0700 - val_acc: 0.6615
Epoch 15/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5905 - acc: 0.6879Epoch 00014: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5906 - acc: 0.6878 - val_loss: 0.0698 - val_acc: 0.6616
Epoch 16/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5900 - acc: 0.6893Epoch 00015: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5900 - acc: 0.6893 - val_loss: 0.0698 - val_acc: 0.6609
Epoch 17/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5872 - acc: 0.6894Epoch 00016: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5872 - acc: 0.6893 - val_loss: 0.0697 - val_acc: 0.6634
Epoch 18/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5864 - acc: 0.6897Epoch 00017: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5864 - acc: 0.6896 - val_loss: 0.0702 - val_acc: 0.6624
Epoch 19/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5855 - acc: 0.6909Epoch 00018: val_loss improved from 0.06963 to 0.06955, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.5856 - acc: 0.6909 - val_loss: 0.0696 - val_acc: 0.6635
Epoch 20/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5845 - acc: 0.6937Epoch 00019: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5845 - acc: 0.6936 - val_loss: 0.0699 - val_acc: 0.6645
Epoch 21/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5829 - acc: 0.6940Epoch 00020: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5832 - acc: 0.6938 - val_loss: 0.0703 - val_acc: 0.6638
Epoch 22/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5814 - acc: 0.6938Epoch 00021: val_loss improved from 0.06955 to 0.06953, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.5814 - acc: 0.6939 - val_loss: 0.0695 - val_acc: 0.6634
Epoch 23/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5814 - acc: 0.6949Epoch 00022: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5814 - acc: 0.6949 - val_loss: 0.0697 - val_acc: 0.6640
Epoch 24/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5808 - acc: 0.6956Epoch 00023: val_loss improved from 0.06953 to 0.06950, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.5809 - acc: 0.6956 - val_loss: 0.0695 - val_acc: 0.6644
Epoch 25/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5808 - acc: 0.6955Epoch 00024: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5808 - acc: 0.6955 - val_loss: 0.0703 - val_acc: 0.6652
Epoch 26/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5796 - acc: 0.6957Epoch 00025: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5796 - acc: 0.6957 - val_loss: 0.0698 - val_acc: 0.6641
Epoch 27/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5790 - acc: 0.6959Epoch 00026: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5792 - acc: 0.6957 - val_loss: 0.0699 - val_acc: 0.6653
Epoch 28/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5785 - acc: 0.6967Epoch 00027: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5784 - acc: 0.6969 - val_loss: 0.0697 - val_acc: 0.6668
Epoch 29/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5778 - acc: 0.6980Epoch 00028: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5778 - acc: 0.6979 - val_loss: 0.0695 - val_acc: 0.6651
Epoch 30/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5762 - acc: 0.6970Epoch 00029: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5761 - acc: 0.6971 - val_loss: 0.0695 - val_acc: 0.6657
Epoch 31/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5772 - acc: 0.6983Epoch 00030: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5770 - acc: 0.6984 - val_loss: 0.0696 - val_acc: 0.6663
Epoch 32/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5767 - acc: 0.6985Epoch 00031: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5766 - acc: 0.6985 - val_loss: 0.0696 - val_acc: 0.6643
Epoch 33/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5752 - acc: 0.6988Epoch 00032: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5752 - acc: 0.6988 - val_loss: 0.0696 - val_acc: 0.6654
Epoch 34/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.6984Epoch 00033: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5746 - acc: 0.6983 - val_loss: 0.0699 - val_acc: 0.6654
Epoch 35/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5754 - acc: 0.6996Epoch 00034: val_loss did not improve
70000/70000 [==============================] - 45s - loss: 0.5754 - acc: 0.6996 - val_loss: 0.0696 - val_acc: 0.6652
Epoch 36/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5729 - acc: 0.6996Epoch 00035: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5729 - acc: 0.6996 - val_loss: 0.0697 - val_acc: 0.6658
Epoch 37/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5746 - acc: 0.7001Epoch 00036: val_loss improved from 0.06950 to 0.06942, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.5747 - acc: 0.6998 - val_loss: 0.0694 - val_acc: 0.6648
Epoch 38/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5720 - acc: 0.7012Epoch 00037: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5721 - acc: 0.7011 - val_loss: 0.0698 - val_acc: 0.6649
Epoch 39/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7010Epoch 00038: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5728 - acc: 0.7008 - val_loss: 0.0695 - val_acc: 0.6652
Epoch 40/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5719 - acc: 0.7016Epoch 00039: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5719 - acc: 0.7017 - val_loss: 0.0695 - val_acc: 0.6650
Epoch 41/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5725 - acc: 0.7024Epoch 00040: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5725 - acc: 0.7023 - val_loss: 0.0696 - val_acc: 0.6661
Epoch 42/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5699 - acc: 0.7011Epoch 00041: val_loss improved from 0.06942 to 0.06936, saving model to keras_Hut1v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 46s - loss: 0.5699 - acc: 0.7011 - val_loss: 0.0694 - val_acc: 0.6635
Epoch 43/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5712 - acc: 0.7025Epoch 00042: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5713 - acc: 0.7025 - val_loss: 0.0698 - val_acc: 0.6634
Epoch 44/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5700 - acc: 0.7030Epoch 00043: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5701 - acc: 0.7029 - val_loss: 0.0696 - val_acc: 0.6638
Epoch 45/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5698 - acc: 0.7026Epoch 00044: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5697 - acc: 0.7026 - val_loss: 0.0700 - val_acc: 0.6645
Epoch 46/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5697 - acc: 0.7021Epoch 00045: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5698 - acc: 0.7021 - val_loss: 0.0698 - val_acc: 0.6642
Epoch 47/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5701 - acc: 0.7028Epoch 00046: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5701 - acc: 0.7028 - val_loss: 0.0697 - val_acc: 0.6652
Epoch 48/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5681 - acc: 0.7053Epoch 00047: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5682 - acc: 0.7052 - val_loss: 0.0694 - val_acc: 0.6641
Epoch 49/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5698 - acc: 0.7042Epoch 00048: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5696 - acc: 0.7044 - val_loss: 0.0695 - val_acc: 0.6651
Epoch 50/50
69800/70000 [============================>.] - ETA: 0s - loss: 0.5685 - acc: 0.7037Epoch 00049: val_loss did not improve
70000/70000 [==============================] - 46s - loss: 0.5685 - acc: 0.7038 - val_loss: 0.0697 - val_acc: 0.6648
                         : Elapsed time for training with 70000 events: 2.32e+03 sec         
                         : Creating xml weight file: keras_Hut1v2/weights/TMVAClassification_PyKeras.weights.xml
                         : Creating standalone class: keras_Hut1v2/weights/TMVAClassification_PyKeras.class.C
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
BDT                      : Ranking result (top variable is best ranked)
                         : -------------------------------------------------
                         : Rank : Variable        : Variable Importance
                         : -------------------------------------------------
                         :    1 : DRjet2cvsb      : 2.541e-02
                         :    2 : DRjet2csv       : 2.207e-02
                         :    3 : DRjet31m        : 1.912e-02
                         :    4 : DRjet12m        : 1.828e-02
                         :    5 : DRjet0cvsb      : 1.824e-02
                         :    6 : dibjetsMass     : 1.759e-02
                         :    7 : DRjet3cvsb      : 1.730e-02
                         :    8 : bjetmDR         : 1.699e-02
                         :    9 : DRjet3csv       : 1.666e-02
                         :   10 : DRjet23m        : 1.661e-02
                         :   11 : DRjet0csv       : 1.644e-02
                         :   12 : DRjet12DR       : 1.607e-02
                         :   13 : jet1cvsb        : 1.593e-02
                         :   14 : DRjet3cvsl      : 1.591e-02
                         :   15 : DRjet3m         : 1.562e-02
                         :   16 : DRjet2cvsl      : 1.521e-02
                         :   17 : jet3cvsb        : 1.512e-02
                         :   18 : DRjet0eta       : 1.496e-02
                         :   19 : bjetmDEta       : 1.481e-02
                         :   20 : bjetmDPhi       : 1.474e-02
                         :   21 : lepDPhi         : 1.466e-02
                         :   22 : jet4eta         : 1.460e-02
                         :   23 : DRjet2eta       : 1.437e-02
                         :   24 : jet2cvsb        : 1.432e-02
                         :   25 : DRjet1eta       : 1.416e-02
                         :   26 : DRjet3eta       : 1.408e-02
                         :   27 : DRjet1m         : 1.400e-02
                         :   28 : jet1eta         : 1.389e-02
                         :   29 : jet2eta         : 1.382e-02
                         :   30 : jet4cvsb        : 1.369e-02
                         :   31 : DRjet1cvsb      : 1.360e-02
                         :   32 : DRlepTeta       : 1.358e-02
                         :   33 : DRlepTpt        : 1.335e-02
                         :   34 : jet4csv         : 1.334e-02
                         :   35 : jet4cvsl        : 1.331e-02
                         :   36 : DRlepTm         : 1.315e-02
                         :   37 : jet3eta         : 1.310e-02
                         :   38 : DRjet0cvsl      : 1.306e-02
                         :   39 : DRjet1csv       : 1.281e-02
                         :   40 : DRjet1cvsl      : 1.264e-02
                         :   41 : DRlepWm         : 1.263e-02
                         :   42 : DRjet2m         : 1.248e-02
                         :   43 : DRlepWeta       : 1.219e-02
                         :   44 : DRjet0pt        : 1.213e-02
                         :   45 : jet1cvsl        : 1.182e-02
                         :   46 : jet2cvsl        : 1.179e-02
                         :   47 : jet3csv         : 1.163e-02
                         :   48 : jet3cvsl        : 1.161e-02
                         :   49 : cjetPt          : 1.147e-02
                         :   50 : DRjet23pt       : 1.144e-02
                         :   51 : DRhadTpt        : 1.108e-02
                         :   52 : jet1pt          : 1.104e-02
                         :   53 : DRjet3pt        : 1.103e-02
                         :   54 : jet3m           : 1.088e-02
                         :   55 : ncjets_m        : 1.074e-02
                         :   56 : DRhadTm         : 1.062e-02
                         :   57 : jet2csv         : 1.057e-02
                         :   58 : jet1csv         : 1.051e-02
                         :   59 : DRjet0m         : 1.030e-02
                         :   60 : DRlepWpt        : 1.030e-02
                         :   61 : DRjet12eta      : 1.020e-02
                         :   62 : jet1m           : 1.018e-02
                         :   63 : missingET       : 1.001e-02
                         :   64 : DRjet31pt       : 9.628e-03
                         :   65 : njets           : 9.616e-03
                         :   66 : jet4m           : 9.225e-03
                         :   67 : DRjet23eta      : 9.031e-03
                         :   68 : jet4pt          : 8.987e-03
                         :   69 : DRjet12pt       : 8.833e-03
                         :   70 : DRjet31eta      : 8.796e-03
                         :   71 : DRhadTeta       : 8.615e-03
                         :   72 : DRjet1pt        : 8.491e-03
                         :   73 : DRjet2pt        : 8.277e-03
                         :   74 : bjetPt_dibjetsm : 7.763e-03
                         :   75 : jet3pt          : 7.702e-03
                         :   76 : jet2pt          : 7.420e-03
                         :   77 : nbjets_m        : 7.288e-03
                         :   78 : jet2m           : 7.076e-03
                         : -------------------------------------------------
                         : No variable ranking supplied by classifier: PyKeras
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : Test all methods
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [keras_Hut1v2] : Evaluation of BDT on testing sample (20000 events)
                         : Elapsed time for evaluation of 20000 events: 1.96 sec       
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: keras_Hut1v2/weights/TrainedModel_PyKeras.h5
Factory                  : Evaluate all methods
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [keras_Hut1v2] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            :        Variable               Mean               RMS       [        Min               Max ]
                         : ----------------------------------------------------------------------------------------------
                         :           njets:           4.9699           1.1441   [           4.0000           14.000 ]
                         :        nbjets_m:           3.0536          0.23880   [           3.0000           6.0000 ]
                         :        ncjets_m:          0.64081          0.78193   [           0.0000           6.0000 ]
                         :         lepDPhi:        0.0080912           1.6140   [          -3.1416           3.1411 ]
                         :       missingET:           68.662           49.612   [          0.41146           769.54 ]
                         :         bjetmDR:           1.3874          0.52822   [          0.40171           3.3124 ]
                         :       bjetmDEta:         0.012978          0.94983   [          -3.1368           3.0723 ]
                         :       bjetmDPhi:        -0.012019           1.1408   [          -3.1307           3.1019 ]
                         :     dibjetsMass:           102.76           50.160   [           17.490           877.96 ]
                         : bjetPt_dibjetsm:           108.14           66.465   [           30.256           1400.9 ]
                         :          cjetPt:           90.868           70.702   [           30.002           1054.4 ]
                         :          jet1pt:           143.91           87.678   [           37.762           1400.9 ]
                         :         jet1eta:        0.0059639           1.0626   [          -2.3999           2.3967 ]
                         :           jet1m:           246.22           209.89   [           40.703           2785.1 ]
                         :         jet1csv:          0.76019          0.32813   [         0.039414          0.99943 ]
                         :        jet1cvsl:          0.55672          0.48572   [         -0.64354          0.99685 ]
                         :        jet1cvsb:         -0.29213          0.52773   [         -0.98271          0.83928 ]
                         :          jet2pt:           97.662           52.484   [           32.085           1149.7 ]
                         :         jet2eta:        0.0016417           1.0677   [          -2.3997           2.3971 ]
                         :           jet2m:           165.89           127.95   [           34.238           2437.0 ]
                         :         jet2csv:          0.74861          0.33840   [         0.047415          0.99961 ]
                         :        jet2cvsl:          0.55782          0.49837   [         -0.65479          0.99712 ]
                         :        jet2cvsb:         -0.29049          0.53871   [         -0.98288          0.85085 ]
                         :          jet3pt:           70.400           32.600   [           30.225           597.83 ]
                         :         jet3eta:       -0.0022110           1.1027   [          -2.3990           2.3995 ]
                         :           jet3m:           123.68           90.489   [           30.917           1467.9 ]
                         :         jet3csv:          0.70291          0.35529   [         0.047237          0.99959 ]
                         :        jet3cvsl:          0.49827          0.52429   [         -0.76039          0.99709 ]
                         :        jet3cvsb:         -0.22389          0.55377   [         -0.98400          0.83794 ]
                         :          jet4pt:           52.126           21.677   [           30.002           451.44 ]
                         :         jet4eta:        0.0030318           1.1323   [          -2.4000           2.3997 ]
                         :           jet4m:           94.380           66.932   [           30.461           827.73 ]
                         :         jet4csv:          0.66764          0.35893   [         0.043435          0.99963 ]
                         :        jet4cvsl:          0.44003          0.53896   [         -0.69492          0.99627 ]
                         :        jet4cvsb:         -0.16673          0.55161   [         -0.98613          0.84578 ]
                         :        DRlepWpt:           115.45           76.760   [          0.13619           978.38 ]
                         :       DRlepWeta:         0.014190          0.88640   [          -6.1349           5.4076 ]
                         :         DRlepWm:           94.685           48.494   [          0.39319           525.05 ]
                         :        DRjet0pt:           112.16           85.320   [           30.011           1336.7 ]
                         :       DRjet0eta:         0.012211           1.1702   [          -2.3999           2.3995 ]
                         :         DRjet0m:           15.043           9.9176   [           1.9269           177.82 ]
                         :       DRjet0csv:          0.67467          0.35919   [         0.039414          0.99956 ]
                         :      DRjet0cvsl:          0.44590          0.52746   [         -0.64354          0.99685 ]
                         :      DRjet0cvsb:         -0.17945          0.55286   [         -0.98152          0.85085 ]
                         :        DRjet1pt:           81.095           52.870   [           30.002           928.19 ]
                         :       DRjet1eta:        0.0089183          0.98858   [          -2.3977           2.3978 ]
                         :         DRjet1m:           11.857           7.0612   [           2.6340           145.40 ]
                         :       DRjet1csv:          0.97978         0.026918   [          0.85121          0.99963 ]
                         :      DRjet1cvsl:          0.87902          0.16448   [         -0.58671          0.99715 ]
                         :      DRjet1cvsb:         -0.73055          0.24575   [         -0.98613          0.67683 ]
                         :        DRjet2pt:           82.405           57.655   [           30.002           1264.4 ]
                         :       DRjet2eta:       -0.0091700           1.0483   [          -2.3980           2.3966 ]
                         :         DRjet2m:           12.111           7.9471   [           2.5847           174.23 ]
                         :       DRjet2csv:          0.93310         0.045428   [          0.84840          0.99942 ]
                         :      DRjet2cvsl:          0.81492          0.22216   [         -0.53934          0.99709 ]
                         :      DRjet2cvsb:         -0.44544          0.33974   [         -0.98530          0.73015 ]
                         :        DRjet3pt:           71.654           49.654   [           30.002           1400.9 ]
                         :       DRjet3eta:        0.0049157           1.0822   [          -2.4000           2.3994 ]
                         :         DRjet3m:           10.892           7.0335   [           1.7574           296.17 ]
                         :       DRjet3csv:          0.38779          0.31070   [         0.047237          0.99882 ]
                         :      DRjet3cvsl:         0.038308          0.45569   [         -0.82989          0.99619 ]
                         :      DRjet3cvsb:          0.25391          0.37445   [         -0.96286          0.84578 ]
                         :       DRjet12pt:           137.18           78.943   [           2.5115           1298.1 ]
                         :      DRjet12eta:      -0.00024901           1.1325   [          -4.8967           4.6205 ]
                         :        DRjet12m:           109.89           56.317   [           18.699           877.96 ]
                         :       DRjet12DR:           1.5168          0.60714   [          0.40298           4.6346 ]
                         :       DRjet23pt:           123.75           77.532   [          0.73626           1450.4 ]
                         :      DRjet23eta:        0.0011110           1.2652   [          -5.0238           5.9117 ]
                         :        DRjet23m:           107.53           67.363   [           17.333           965.16 ]
                         :       DRjet31pt:           121.47           74.773   [          0.64226           1511.0 ]
                         :      DRjet31eta:         0.012530           1.2409   [          -6.0343           5.2014 ]
                         :        DRjet31m:           108.37           64.509   [           17.711           1274.5 ]
                         :        DRlepTpt:           161.76           98.773   [           1.1315           1459.7 ]
                         :       DRlepTeta:         0.017397           1.2280   [          -6.1058           5.6176 ]
                         :         DRlepTm:           252.22           155.54   [           39.864           2961.7 ]
                         :        DRhadTpt:           174.34           96.136   [           3.5177           1559.9 ]
                         :       DRhadTeta:        0.0066662           1.2470   [          -5.2776           6.4020 ]
                         :         DRhadTm:           196.41           90.047   [           38.780           1356.8 ]
                         : ----------------------------------------------------------------------------------------------
                         : 
                         : <PlotVariables> Will not produce scatter plots ==> 
                         : |  The number of 78 input variables and 0 target values would require 3003 two-dimensional
                         : |  histograms, which would occupy the computer's memory. Note that this
                         : |  suppression does not have any consequences for your analysis, other
                         : |  than not disposing of these scatter plots. You can modify the maximum
                         : |  number of input variables allowed to generate scatter plots in your
                         : |  script via the command line:
                         : |  "(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;"
                         : 
                         : Some more output
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :        Variable               Mean               RMS       [        Min               Max ]
                         : ----------------------------------------------------------------------------------------------
                         :           njets:        0.0049218          0.99167   [          -3.0148           5.7307 ]
                         :        nbjets_m:       -0.0054763          0.99472   [          -3.2074           3.5113 ]
                         :        ncjets_m:        -0.012350          0.97970   [          -5.7307           4.1960 ]
                         :         lepDPhi:         0.012835           1.0075   [          -3.0306           5.7307 ]
                         :       missingET:       -0.0050765          0.99067   [          -3.3762           5.7307 ]
                         :         bjetmDR:         0.016697          0.99527   [          -3.3233           5.7307 ]
                         :       bjetmDEta:        0.0015989          0.98671   [          -3.1631           3.7774 ]
                         :       bjetmDPhi:       -0.0093828          0.99592   [          -3.1389           3.6210 ]
                         :     dibjetsMass:      -0.00027195          0.97294   [          -3.1530           5.7307 ]
                         : bjetPt_dibjetsm:         0.015425          0.98949   [          -3.1237           5.7307 ]
                         :          cjetPt:        0.0025192          0.98594   [          -5.7307           5.7307 ]
                         :          jet1pt:       0.00073031          0.98349   [          -3.2373           4.0320 ]
                         :         jet1eta:       0.00080472          0.98059   [          -3.1769           5.7307 ]
                         :           jet1m:       -0.0050489          0.98182   [          -3.2345           3.5450 ]
                         :         jet1csv:         0.011440          0.97854   [          -3.1276           5.7307 ]
                         :        jet1cvsl:         0.018706          0.97999   [          -3.3762           5.7307 ]
                         :        jet1cvsb:        -0.023920          0.99281   [          -3.1780           5.7307 ]
                         :          jet2pt:       -0.0069476          0.98022   [          -3.3572           3.3924 ]
                         :         jet2eta:       -0.0022160          0.97715   [          -3.4379           3.5917 ]
                         :           jet2m:       -0.0062522          0.97902   [          -3.9915           5.7307 ]
                         :         jet2csv:        0.0075017          0.97096   [          -3.1331           5.7307 ]
                         :        jet2cvsl:       -0.0024995          0.97635   [          -3.5338           5.7307 ]
                         :        jet2cvsb:        -0.018718          0.98407   [          -3.0557           3.8953 ]
                         :          jet3pt:        0.0024641          0.99950   [          -3.2700           5.7307 ]
                         :         jet3eta:       -0.0098268          0.99290   [          -3.2384           3.7463 ]
                         :           jet3m:         0.013217          0.98975   [          -3.2168           3.4372 ]
                         :         jet3csv:        0.0043126          0.97858   [          -3.1667           3.4148 ]
                         :        jet3cvsl:       -0.0053038          0.98549   [          -3.1122           5.7307 ]
                         :        jet3cvsb:        -0.010581          0.99157   [          -3.1534           5.7307 ]
                         :          jet4pt:       -0.0038171          0.98213   [          -3.1337           5.7307 ]
                         :         jet4eta:        0.0075535          0.98536   [          -3.0726           5.7307 ]
                         :           jet4m:       -0.0017298          0.98493   [          -3.0395           3.6977 ]
                         :         jet4csv:        0.0037940          0.98083   [          -3.1365           5.7307 ]
                         :        jet4cvsl:        0.0026491          0.98281   [          -3.4215           3.5744 ]
                         :        jet4cvsb:        -0.019872          0.98868   [          -3.1494           5.7307 ]
                         :        DRlepWpt:        0.0070684          0.99514   [          -3.0830           5.7307 ]
                         :       DRlepWeta:         0.013924          0.99903   [          -5.7307           5.7307 ]
                         :         DRlepWm:         0.014754           1.0021   [          -3.0383           3.3854 ]
                         :        DRjet0pt:       -0.0093331          0.98851   [          -3.0970           5.7307 ]
                         :       DRjet0eta:         0.014318          0.99651   [          -3.0841           5.7307 ]
                         :         DRjet0m:        0.0031822          0.98478   [          -3.9275           5.7307 ]
                         :       DRjet0csv:         0.012089          0.98195   [          -5.7307           5.7307 ]
                         :      DRjet0cvsl:         0.012402          0.98596   [          -3.2675           5.7307 ]
                         :      DRjet0cvsb:       -0.0085071          0.99491   [          -3.1460           5.7307 ]
                         :        DRjet1pt:        0.0046047          0.98362   [          -3.1736           5.7307 ]
                         :       DRjet1eta:        0.0051885          0.98210   [          -3.2297           3.9424 ]
                         :         DRjet1m:        0.0018509           1.0021   [          -3.1890           5.7307 ]
                         :       DRjet1csv:        0.0066457          0.96151   [          -3.0670           5.7307 ]
                         :      DRjet1cvsl:       -0.0035593          0.97937   [          -3.1590           5.7307 ]
                         :      DRjet1cvsb:        -0.023943          0.98141   [          -3.0354           5.7307 ]
                         :        DRjet2pt:         0.020481          0.98998   [          -5.7307           5.7307 ]
                         :       DRjet2eta:       -0.0094043          0.98474   [          -3.0946           3.2048 ]
                         :         DRjet2m:       -0.0024324           1.0007   [          -3.3127           5.7307 ]
                         :       DRjet2csv:         0.026826          0.99037   [          -3.1591           3.5178 ]
                         :      DRjet2cvsl:         0.011861          0.96763   [          -3.0494           3.4037 ]
                         :      DRjet2cvsb:        -0.064692          0.99226   [          -3.1891           3.6352 ]
                         :        DRjet3pt:        0.0023527          0.98804   [          -3.1805           5.7307 ]
                         :       DRjet3eta:      -0.00038114          0.98985   [          -3.2485           5.7307 ]
                         :         DRjet3m:         0.010026          0.99371   [          -3.0577           5.7307 ]
                         :       DRjet3csv:        0.0098532          0.98522   [          -3.1497           3.5044 ]
                         :      DRjet3cvsl:        0.0019299          0.97871   [          -3.5716           3.7220 ]
                         :      DRjet3cvsb:       -0.0013236          0.98918   [          -3.3334           3.4120 ]
                         :       DRjet12pt:         0.011127           1.0008   [          -3.2227           3.7123 ]
                         :      DRjet12eta:       -0.0025408          0.98981   [          -3.0508           5.7307 ]
                         :        DRjet12m:        0.0016116          0.97814   [          -3.0977           5.7307 ]
                         :       DRjet12DR:         0.021416          0.98845   [          -3.5830           3.8346 ]
                         :       DRjet23pt:         0.019521          0.97814   [          -3.0887           5.7307 ]
                         :      DRjet23eta:        0.0017338          0.97935   [          -3.1309           3.8189 ]
                         :        DRjet23m:       -0.0053109          0.99149   [          -3.9532           3.5659 ]
                         :       DRjet31pt:         0.016288          0.99494   [          -3.0721           3.5994 ]
                         :      DRjet31eta:        0.0044954          0.99376   [          -3.1340           5.7307 ]
                         :        DRjet31m:        -0.014783          0.97690   [          -3.0332           3.4796 ]
                         :        DRlepTpt:        0.0069262           1.0004   [          -3.0734           3.5274 ]
                         :       DRlepTeta:         0.011157          0.98828   [          -3.1456           5.7307 ]
                         :         DRlepTm:        -0.013357          0.98281   [          -3.2584           5.7307 ]
                         :        DRhadTpt:        0.0044564          0.99644   [          -3.0947           5.7307 ]
                         :       DRhadTeta:        0.0073099          0.98654   [          -3.0696           5.7307 ]
                         :         DRhadTm:       -0.0084664          0.98237   [          -5.7307           3.9272 ]
                         : ----------------------------------------------------------------------------------------------
PyKeras                  : [keras_Hut1v2] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :        Variable               Mean               RMS       [        Min               Max ]
                         : ----------------------------------------------------------------------------------------------
                         :           njets:        0.0049218          0.99167   [          -3.0148           5.7307 ]
                         :        nbjets_m:       -0.0054763          0.99472   [          -3.2074           3.5113 ]
                         :        ncjets_m:        -0.012350          0.97970   [          -5.7307           4.1960 ]
                         :         lepDPhi:         0.012835           1.0075   [          -3.0306           5.7307 ]
                         :       missingET:       -0.0050765          0.99067   [          -3.3762           5.7307 ]
                         :         bjetmDR:         0.016697          0.99527   [          -3.3233           5.7307 ]
                         :       bjetmDEta:        0.0015989          0.98671   [          -3.1631           3.7774 ]
                         :       bjetmDPhi:       -0.0093828          0.99592   [          -3.1389           3.6210 ]
                         :     dibjetsMass:      -0.00027195          0.97294   [          -3.1530           5.7307 ]
                         : bjetPt_dibjetsm:         0.015425          0.98949   [          -3.1237           5.7307 ]
                         :          cjetPt:        0.0025192          0.98594   [          -5.7307           5.7307 ]
                         :          jet1pt:       0.00073031          0.98349   [          -3.2373           4.0320 ]
                         :         jet1eta:       0.00080472          0.98059   [          -3.1769           5.7307 ]
                         :           jet1m:       -0.0050489          0.98182   [          -3.2345           3.5450 ]
                         :         jet1csv:         0.011440          0.97854   [          -3.1276           5.7307 ]
                         :        jet1cvsl:         0.018706          0.97999   [          -3.3762           5.7307 ]
                         :        jet1cvsb:        -0.023920          0.99281   [          -3.1780           5.7307 ]
                         :          jet2pt:       -0.0069476          0.98022   [          -3.3572           3.3924 ]
                         :         jet2eta:       -0.0022160          0.97715   [          -3.4379           3.5917 ]
                         :           jet2m:       -0.0062522          0.97902   [          -3.9915           5.7307 ]
                         :         jet2csv:        0.0075017          0.97096   [          -3.1331           5.7307 ]
                         :        jet2cvsl:       -0.0024995          0.97635   [          -3.5338           5.7307 ]
                         :        jet2cvsb:        -0.018718          0.98407   [          -3.0557           3.8953 ]
                         :          jet3pt:        0.0024641          0.99950   [          -3.2700           5.7307 ]
                         :         jet3eta:       -0.0098268          0.99290   [          -3.2384           3.7463 ]
                         :           jet3m:         0.013217          0.98975   [          -3.2168           3.4372 ]
                         :         jet3csv:        0.0043126          0.97858   [          -3.1667           3.4148 ]
                         :        jet3cvsl:       -0.0053038          0.98549   [          -3.1122           5.7307 ]
                         :        jet3cvsb:        -0.010581          0.99157   [          -3.1534           5.7307 ]
                         :          jet4pt:       -0.0038171          0.98213   [          -3.1337           5.7307 ]
                         :         jet4eta:        0.0075535          0.98536   [          -3.0726           5.7307 ]
                         :           jet4m:       -0.0017298          0.98493   [          -3.0395           3.6977 ]
                         :         jet4csv:        0.0037940          0.98083   [          -3.1365           5.7307 ]
                         :        jet4cvsl:        0.0026491          0.98281   [          -3.4215           3.5744 ]
                         :        jet4cvsb:        -0.019872          0.98868   [          -3.1494           5.7307 ]
                         :        DRlepWpt:        0.0070684          0.99514   [          -3.0830           5.7307 ]
                         :       DRlepWeta:         0.013924          0.99903   [          -5.7307           5.7307 ]
                         :         DRlepWm:         0.014754           1.0021   [          -3.0383           3.3854 ]
                         :        DRjet0pt:       -0.0093331          0.98851   [          -3.0970           5.7307 ]
                         :       DRjet0eta:         0.014318          0.99651   [          -3.0841           5.7307 ]
                         :         DRjet0m:        0.0031822          0.98478   [          -3.9275           5.7307 ]
                         :       DRjet0csv:         0.012089          0.98195   [          -5.7307           5.7307 ]
                         :      DRjet0cvsl:         0.012402          0.98596   [          -3.2675           5.7307 ]
                         :      DRjet0cvsb:       -0.0085071          0.99491   [          -3.1460           5.7307 ]
                         :        DRjet1pt:        0.0046047          0.98362   [          -3.1736           5.7307 ]
                         :       DRjet1eta:        0.0051885          0.98210   [          -3.2297           3.9424 ]
                         :         DRjet1m:        0.0018509           1.0021   [          -3.1890           5.7307 ]
                         :       DRjet1csv:        0.0066457          0.96151   [          -3.0670           5.7307 ]
                         :      DRjet1cvsl:       -0.0035593          0.97937   [          -3.1590           5.7307 ]
                         :      DRjet1cvsb:        -0.023943          0.98141   [          -3.0354           5.7307 ]
                         :        DRjet2pt:         0.020481          0.98998   [          -5.7307           5.7307 ]
                         :       DRjet2eta:       -0.0094043          0.98474   [          -3.0946           3.2048 ]
                         :         DRjet2m:       -0.0024324           1.0007   [          -3.3127           5.7307 ]
                         :       DRjet2csv:         0.026826          0.99037   [          -3.1591           3.5178 ]
                         :      DRjet2cvsl:         0.011861          0.96763   [          -3.0494           3.4037 ]
                         :      DRjet2cvsb:        -0.064692          0.99226   [          -3.1891           3.6352 ]
                         :        DRjet3pt:        0.0023527          0.98804   [          -3.1805           5.7307 ]
                         :       DRjet3eta:      -0.00038114          0.98985   [          -3.2485           5.7307 ]
                         :         DRjet3m:         0.010026          0.99371   [          -3.0577           5.7307 ]
                         :       DRjet3csv:        0.0098532          0.98522   [          -3.1497           3.5044 ]
                         :      DRjet3cvsl:        0.0019299          0.97871   [          -3.5716           3.7220 ]
                         :      DRjet3cvsb:       -0.0013236          0.98918   [          -3.3334           3.4120 ]
                         :       DRjet12pt:         0.011127           1.0008   [          -3.2227           3.7123 ]
                         :      DRjet12eta:       -0.0025408          0.98981   [          -3.0508           5.7307 ]
                         :        DRjet12m:        0.0016116          0.97814   [          -3.0977           5.7307 ]
                         :       DRjet12DR:         0.021416          0.98845   [          -3.5830           3.8346 ]
                         :       DRjet23pt:         0.019521          0.97814   [          -3.0887           5.7307 ]
                         :      DRjet23eta:        0.0017338          0.97935   [          -3.1309           3.8189 ]
                         :        DRjet23m:       -0.0053109          0.99149   [          -3.9532           3.5659 ]
                         :       DRjet31pt:         0.016288          0.99494   [          -3.0721           3.5994 ]
                         :      DRjet31eta:        0.0044954          0.99376   [          -3.1340           5.7307 ]
                         :        DRjet31m:        -0.014783          0.97690   [          -3.0332           3.4796 ]
                         :        DRlepTpt:        0.0069262           1.0004   [          -3.0734           3.5274 ]
                         :       DRlepTeta:         0.011157          0.98828   [          -3.1456           5.7307 ]
                         :         DRlepTm:        -0.013357          0.98281   [          -3.2584           5.7307 ]
                         :        DRhadTpt:        0.0044564          0.99644   [          -3.0947           5.7307 ]
                         :       DRhadTeta:        0.0073099          0.98654   [          -3.0696           5.7307 ]
                         :         DRhadTm:       -0.0084664          0.98237   [          -5.7307           3.9272 ]
                         : ----------------------------------------------------------------------------------------------
                         : 
                         : <PlotVariables> Will not produce scatter plots ==> 
                         : |  The number of 78 input variables and 0 target values would require 3003 two-dimensional
                         : |  histograms, which would occupy the computer's memory. Note that this
                         : |  suppression does not have any consequences for your analysis, other
                         : |  than not disposing of these scatter plots. You can modify the maximum
                         : |  number of input variables allowed to generate scatter plots in your
                         : |  script via the command line:
                         : |  "(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;"
                         : 
                         : Some more output
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : keras_Hut1v2  BDT            : 0.729
                         : keras_Hut1v2  PyKeras        : 0.727
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : keras_Hut1v2         BDT            : 0.094 (0.112)       0.367 (0.386)      0.635 (0.654)
                         : keras_Hut1v2         PyKeras        : 0.090 (0.127)       0.355 (0.406)      0.632 (0.668)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:keras_Hut1v2     : Created tree 'TestTree' with 20000 events
                         : 
Dataset:keras_Hut1v2     : Created tree 'TrainTree' with 70000 events
                         : 
Factory                  : Thank you for using TMVA!
                         : For citation information, please visit: http://tmva.sf.net/citeTMVA.html
--- Launch TMVA GUI to view input file: output_keras.root
=== Note: inactive buttons indicate classifiers that were not trained, ===
===       or functionalities that were not invoked during the training ===
